{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDWRITTEN MATHEMATICAL EQUATION SOLVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Dataset\n",
    "#MNIST DATASET\n",
    "#85709 images\n",
    "#operators are numbered as 10,11,12,13 for /,+.-,* respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the label\n",
    "y = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the label\n",
    "X= dataset.drop(labels = [\"label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\91931\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11    22164\n",
       "12    21387\n",
       "1      4684\n",
       "7      4401\n",
       "3      4351\n",
       "9      4188\n",
       "2      4177\n",
       "6      4137\n",
       "0      4132\n",
       "4      4072\n",
       "8      4063\n",
       "5      3795\n",
       "13       80\n",
       "10       78\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#overview of dataset\n",
    "g = sns.countplot(y)\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grayscale normalization\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the dataset to fit standard of a 4dtensor of shape\n",
    "X = X.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical conversion of label\n",
    "y = to_categorical(y, num_classes = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#90% training and 10% validation split\n",
    "random_seed = 2\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1 , random_state = random_seed, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the instance of the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers to the models\n",
    "#layer 1\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 2\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect layer and its output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(14, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting optimizer\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay=0.0 )\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = \"val_accuracy\",\n",
    "                                            patience = 3,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            min_lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augumentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-964ddbef4bcc>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "896/896 [==============================] - 415s 464ms/step - loss: 0.2697 - accuracy: 0.9181 - val_loss: 0.0606 - val_accuracy: 0.9796\n",
      "Epoch 2/5\n",
      "896/896 [==============================] - 397s 443ms/step - loss: 0.0820 - accuracy: 0.9751 - val_loss: 0.0354 - val_accuracy: 0.9901\n",
      "Epoch 3/5\n",
      "896/896 [==============================] - 373s 417ms/step - loss: 0.0648 - accuracy: 0.9813 - val_loss: 0.0316 - val_accuracy: 0.9918\n",
      "Epoch 4/5\n",
      "896/896 [==============================] - 428s 478ms/step - loss: 0.0582 - accuracy: 0.9834 - val_loss: 0.0329 - val_accuracy: 0.9916\n",
      "Epoch 5/5\n",
      "896/896 [==============================] - 472s 526ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.0268 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "#fitting the model\n",
    "epochs = 5\n",
    "batch_size = 86\n",
    "history = model.fit_generator(\n",
    "                                datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                                epochs = epochs, #An epoch is an iteration over the entire x and y data provided\n",
    "                                validation_data = (X_val,y_val), #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                                verbose = 1, #output\n",
    "                                steps_per_epoch=X_train.shape[0] // batch_size,  # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
    "                                callbacks=[learning_rate_reduction]                            \n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model took about 35 mins to train and reached a validation accuracy of 99.30 % after the 5th epoch.\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "from PIL import Image\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading image in grayscale\n",
    "image = Image.open(\"testing.png\").convert(\"L\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing to 28 height pixels\n",
    "w = image.size[0]\n",
    "h = image.size[1]\n",
    "r = w / h # aspect ratio\n",
    "new_w = int(r * 28)\n",
    "new_h = 28\n",
    "new_image = image.resize((new_w, new_h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to a numpy array\n",
    "new_image_arr=np.array(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverting the image to make background = 0'\n",
    "new_inv_image_arr = 255 - new_image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling the image\n",
    "final_image_arr = new_inv_image_arr / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting image array into individual element arrays using non zero columns\n",
    "m = final_image_arr.any(0)\n",
    "out = [final_image_arr[:,[*g]] for k, g in groupby(np.arange(len(m)), lambda x: m[x] != 0) if k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the element arrays to resize them to match input #\n",
    "#criteria of the model = [mini_batch_size, height, width, channels]\n",
    "num_of_elements = len(out)\n",
    "elements_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, num_of_elements):\n",
    "    img = out[x]\n",
    "    \n",
    "    #adding 0 value columns as fillers\n",
    "    width = img.shape[1]\n",
    "    filler = (final_image_arr.shape[0] - width) / 2\n",
    "    \n",
    "    if filler.is_integer() == False:    #odd number of filler columns\n",
    "        filler_l = int(filler)\n",
    "        filler_r = int(filler) + 1\n",
    "    else:                               #even number of filler columns\n",
    "        filler_l = int(filler)\n",
    "        filler_r = int(filler)\n",
    "    \n",
    "    arr_l = np.zeros((final_image_arr.shape[0], filler_l)) #left fillers\n",
    "    arr_r = np.zeros((final_image_arr.shape[0], filler_r)) #right fillers\n",
    "    \n",
    "    #concatinating the left and right fillers\n",
    "    help_ = np.concatenate((arr_l, img), axis= 1)\n",
    "    element_arr = np.concatenate((help_, arr_r), axis= 1)\n",
    "    \n",
    "    element_arr.resize(28, 28, 1) #resize array 2d to 3d\n",
    "    #storing all elements in a list\n",
    "    elements_list.append(element_arr)\n",
    "elements_array = np.array(elements_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping to fit model input criteria'\n",
    "elements_array = elements_array.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the created model'\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "elements_pred =  model.predict(elements_array)\n",
    "elements_pred = np.argmax(elements_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 28, 28, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_array.shape\n",
    "#[mini batch size,height,width,channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5 13  2 11  9  5 12  5]\n"
     ]
    }
   ],
   "source": [
    "print(elements_pred)\n",
    "#13== X\n",
    "#11== +\n",
    "#12== -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the evaluator\n",
    "def math_expression_generator(arr):\n",
    "    \n",
    "    op = {\n",
    "              10,   # = \"/\"\n",
    "              11,   # = \"+\"\n",
    "              12,   # = \"-\"\n",
    "              13    # = \"*\"\n",
    "                  }   \n",
    "    \n",
    "    m_exp = []\n",
    "    temp = []\n",
    "        \n",
    "    #creating a list separating all elements'\n",
    "    for item in arr:\n",
    "        if item not in op:\n",
    "            temp.append(item)\n",
    "        else:\n",
    "            m_exp.append(temp)\n",
    "            m_exp.append(item)\n",
    "            temp = []\n",
    "    if temp:\n",
    "        m_exp.append(temp)\n",
    "        \n",
    "    #converting the elements to numbers and operators'\n",
    "    i = 0\n",
    "    num = 0\n",
    "    for item in m_exp:\n",
    "        if type(item) == list:\n",
    "            if not item:\n",
    "                m_exp[i] = \"\"\n",
    "                i = i + 1\n",
    "            else:\n",
    "                num_len = len(item)\n",
    "                for digit in item:\n",
    "                    num_len = num_len - 1\n",
    "                    num = num + ((10 ** num_len) * digit)\n",
    "                m_exp[i] = str(num)\n",
    "                num = 0\n",
    "                i = i + 1\n",
    "        else:\n",
    "            m_exp[i] = str(item)\n",
    "            m_exp[i] = m_exp[i].replace(\"10\",\"/\")\n",
    "            m_exp[i] = m_exp[i].replace(\"11\",\"+\")\n",
    "            m_exp[i] = m_exp[i].replace(\"12\",\"-\")\n",
    "            m_exp[i] = m_exp[i].replace(\"13\",\"*\")\n",
    "            \n",
    "            i = i + 1\n",
    "    \n",
    "    \n",
    "    #joining the list of strings to create the mathematical expression'\n",
    "    separator = ' '\n",
    "    m_exp_str = separator.join(m_exp)\n",
    "    \n",
    "    return (m_exp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the mathematical expression\n",
    "m_exp_str = math_expression_generator(elements_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 * 2 + 95 - 5 = 180\n"
     ]
    }
   ],
   "source": [
    "#calculating the mathematical expression using eval()'\n",
    "while True:\n",
    "    try:\n",
    "        answer = eval(m_exp_str)    #evaluating the answer\n",
    "        answer = round(answer, 2)\n",
    "        equation  = m_exp_str + \" = \" + str(answer)\n",
    "        print(equation)   #printing the equation\n",
    "        break\n",
    "\n",
    "    except SyntaxError:\n",
    "        print(\"Invalid predicted expression!!\")\n",
    "        print(\"Following is the predicted expression:\")\n",
    "        print(m_exp_str)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_str=math_expression_generator(elements_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 * 2 + 95 - 5\n"
     ]
    }
   ],
   "source": [
    "print(m_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 * 2 + 95 - 5 = 180\n"
     ]
    }
   ],
   "source": [
    "print(equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2c0d274eac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x2c0d1b55d60>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from itertools import groupby\n",
    "\n",
    "# load the model\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "\n",
    "def solve_eqn(image):\n",
    "    w = image.size[0]\n",
    "    h = image.size[1]\n",
    "    r = w / h # aspect ratio\n",
    "    new_w = int(r * 28)\n",
    "    new_h = 28\n",
    "    image = image.resize((new_w, new_h))\n",
    "    new_image_arr=np.array(image)\n",
    "    new_inv_image_arr = 255 - new_image_arr\n",
    "    final_image_arr = new_inv_image_arr / 255.0\n",
    "    m = final_image_arr.any(0)\n",
    "    out = [final_image_arr[:,[*g]] for k, g in groupby(np.arange(len(m)), lambda x: m[x] != 0) if k]\n",
    "    num_of_elements = len(out)\n",
    "    elements_list = []\n",
    "    for x in range(0, num_of_elements):\n",
    "        img = out[x]\n",
    "\n",
    "        #adding 0 value columns as fillers\n",
    "        width = img.shape[1]\n",
    "        filler = (final_image_arr.shape[0] - width) / 2\n",
    "\n",
    "        if filler.is_integer() == False:    #odd number of filler columns\n",
    "            filler_l = int(filler)\n",
    "            filler_r = int(filler) + 1\n",
    "        else:                               #even number of filler columns\n",
    "            filler_l = int(filler)\n",
    "            filler_r = int(filler)\n",
    "\n",
    "        arr_l = np.zeros((final_image_arr.shape[0], filler_l)) #left fillers\n",
    "        arr_r = np.zeros((final_image_arr.shape[0], filler_r)) #right fillers\n",
    "\n",
    "        #concatinating the left and right fillers\n",
    "        help_ = np.concatenate((arr_l, img), axis= 1)\n",
    "        element_arr = np.concatenate((help_, arr_r), axis= 1)\n",
    "\n",
    "        element_arr.resize(28, 28, 1) #resize array 2d to 3d\n",
    "        #storing all elements in a list\n",
    "        elements_list.append(element_arr)\n",
    "    elements_array = np.array(elements_list)\n",
    "    elements_array = elements_array.reshape(-1, 28, 28, 1)\n",
    "    elements_pred =  model.predict(elements_array)\n",
    "    elements_pred = np.argmax(elements_pred, axis = 1)\n",
    "    m_exp_str = math_expression_generator(elements_pred)\n",
    "    while True:\n",
    "        try:\n",
    "            answer = eval(m_exp_str)    #evaluating the answer\n",
    "            answer = round(answer, 2)\n",
    "            equation  = m_exp_str + \" = \" + str(answer)\n",
    "            #print(equation)   #printing the equation\n",
    "            break\n",
    "\n",
    "        except SyntaxError:\n",
    "            print(\"Invalid predicted expression!!\")\n",
    "            print(\"Following is the predicted expression:\")\n",
    "            print(m_exp_str)\n",
    "            break\n",
    "    return equation\n",
    "\n",
    "image = gr.inputs.Image(shape=None,source=\"upload\",type=\"pil\",image_mode=\"L\")\n",
    "label=gr.outputs.Label(equation)\n",
    "gr.Interface(\n",
    "    fn=solve_eqn,\n",
    "    inputs=image,\n",
    "    outputs=label,\n",
    ").launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
